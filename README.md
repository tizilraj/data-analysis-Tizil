# data-analysis-Tizil














Project Portfolio Document
Data Quality Control Initiative at ABC Enterprises

Project part -2 in UCW 

Project Title:
Implementation of Data Quality Control Measures at ABC Enterprises

Project Objective

The overall objective of this project is to design, create, and implement a comprehensive Data Quality Control (DQC) Framework that will be a foundation of data management and governance at ABC Enterprises. The framework is anticipated to systematically address and resolve existing data quality issues‚Äîi.e., inaccuracies, inconsistencies, incompleteness, and duplication‚Äîof all enterprise data assets.
The DQC program will support the company's strategic goals by rendering high-quality data ubiquitous, available, reliable, and usable for both operational and analytical purposes. It will improve the integrity and validity of data used in critical business processes such as forecasting, performance tracking, regulatory reporting, customer engagement, and executive decision-making

Background and Rationale:

As ABC Enterprises expands its business and data universes, data quality issues in the form of inaccuracies, redundancies, inconsistent formats, and missing values have worsened. These issues compromise the integrity of analytics and reporting solutions, jeopardizing strategic decision-making and compliance requirements. The DQC program addresses these by institutionalizing a formal and sustainable data quality management process

Project Scope:
The scope of the DQC project includes:
‚Ä¢	Data Profiling: Identifying and assessing quality levels across key datasets.
 
2 Data Cleansing: Rectifying data inaccuracies, eliminating duplicates, and standardizing formats.

 
‚Ä¢  Data Validation: Creating automated validation rules and enforcing data integrity checks.
 
 ‚Ä¢  Monitoring & Reporting: Implementing dashboards and alerts to track data quality metrics in real time.
‚Ä¢  Training & Awareness: Building internal capacity and awareness around data quality best practices.
Now I will paste the screen shot of class activity done in week 7, 8 
Week 7 process 
 

Week 8 
 

Methodology:
The project will be executed through the following structured phases:
1. Current State Assessment
Conduct a comprehensive evaluation of the existing data landscape to identify the current maturity of data management practices. This includes:
‚Ä¢	Mapping and analyzing data sources, formats, and storage systems across departments.
‚Ä¢	Reviewing data workflows, ownership, and touchpoints.
‚Ä¢	Identifying high-impact datasets that support key business decisions.
‚Ä¢	Documenting existing pain points such as duplication, fragmentation, and legacy system limitations.
2. Data Profiling
Utilize specialized data profiling tools to systematically evaluate the quality of identified datasets. This diagnostic phase includes:
‚Ä¢	Assessing data against five critical dimensions:
o	Completeness: required values present
o	Uniqueness: duplicate records present
o	Validity:  values conform to defined formats and rules
o	Consistency:  data uniform across systems and time periods
o	Accuracy:  data reflect the real-world entities it describes
‚Ä¢	Producing detailed profiling reports to highlight patterns, anomalies, and risks.
‚Ä¢	Prioritizing areas requiring immediate remediation based on business impact.
. Establish Data Quality Metrics
Define a set of measurable and actionable KPIs that provide visibility into data quality over time. Key tasks include:
‚Ä¢	Identifying data quality indicators such as:
o	Error rates per dataset
o	Duplicate record percentages
o	Compliance with naming and formatting conventions
o	Data freshness and update frequency
‚Ä¢	Setting acceptable thresholds and benchmarks for each metric.
‚Ä¢	Establishing tracking methods for short-term sprints and long-term trend analysis.
4. Data Cleansing
Design and implement data cleansing protocols that enhance the quality of legacy and incoming data. Activities include:
‚Ä¢	Identifying and removing duplicate or obsolete records.
‚Ä¢	Correcting syntax, logic, and format-based errors.
‚Ä¢	Standardizing values using master data references (e.g., country codes, date formats).
‚Ä¢	Applying statistical or rule-based imputation techniques to fill missing values.
‚Ä¢	Automating cleansing routines where feasible to ensure consistency and scalability.
5. Validation Rules and Procedures
Develop a robust framework of validation rules to prevent poor-quality data from entering systems. This phase includes:
‚Ä¢	Creating validation scripts for data entry forms and data pipelines.
‚Ä¢	Defining rules for:
o	Required field completion
o	Acceptable value ranges and formats
o	Referential integrity (e.g., foreign key validation)
‚Ä¢	Providing data entry teams with standardized input templates and field-level tooltips.
‚Ä¢	Embedding validation logic in upstream applications and integration tools.

6. Monitoring and Reporting
Establish dynamic monitoring capabilities that offer real-time insights into data quality status. Steps include:
‚Ä¢	Designing interactive dashboards using visualization platforms such as Power BI or Tableau.
‚Ä¢	Implementing automated alerts for threshold breaches (e.g., >5% error rate).
‚Ä¢	Conducting regular reviews with business units to analyze trends, gaps, and opportunities.
‚Ä¢	Creating executive summary reports and heatmaps to inform data governance stakeholders.

7. Training and Best Practices
Launch a comprehensive training and enablement program to build organization-wide data literacy. Activities include:
‚Ä¢	Hosting workshops tailored to different user groups (data stewards, analysts, business users).
‚Ä¢	Developing self-paced learning modules, user manuals, and quick-reference job aids.
‚Ä¢	Promoting a shared understanding of the value of data quality to daily operations and strategic goals.
‚Ä¢	Establishing accountability structures and recognition systems to incentivize good data practices.

8. Feedback Mechanism
Integrate a continuous feedback loop to enhance the DQC framework based on real-world insights. This includes:
‚Ä¢	Creating feedback channels (e.g., surveys, helpdesk tickets, workshops) for users to report issues and suggest improvements.
‚Ä¢	Analyzing recurring feedback themes to inform future rule adjustments and process redesign.
‚Ä¢	Regularly updating training materials and tools to reflect evolving best practices and user needs.
‚Ä¢	Feeding insights into data governance boards to support enterprise-wide data strategy alignment.

Key Deliverables
‚úÖ Data Quality Control (DQC) Plan
A comprehensive and tactical document that concisely states the project's vision, goals, scope, timeline, roles and responsibilities, and methodological approach. The plan will serve as the central reference point for all stakeholders throughout the initiative and will define the governance framework, quality criteria, and risk mitigation strategies necessary for successful execution.
‚úÖ Data Profiling Reports
Detailed, tool-generated reports evaluating the current state of data within critical systems compared to significant quality dimensions such as completeness, uniqueness, accuracy, consistency, and validity. The reports will highlight specific anomalies, trends, and risk areas, and will rank remediation activities by business impact and data sensitivity.
‚úÖ Validated and Cleansed Datasets
Standardized, cleansed, and de-duplicated data sets that are stringently vetted for consistency and accuracy. These data sets will be integrated into production environments to facilitate reliable analytics, regulatory reporting, machine learning models, and strategic decision-making, with reduced risk of operational errors and ill-informed decisions.
‚úÖ Monitoring Dashboard
An interactive real-time dashboard developed with the assistance of tools like Power BI or Tableau, providing insights into data quality metrics and KPIs. The dashboard will include visualizations for error rates, data freshness, duplication rates, and compliance indicators. This will allow both technical and non-technical users to track progress, detect issues early, and initiate remedial actions proactively.
‚úÖ Training Materials & Knowledge Sessions
Design and develop training program specifications, reference materials, and e-learning materials, as well as in-person or virtual workshops for specific roles (data stewards, analysts, business users). Participants will learn the need for data quality as well as the use of new tools and processes along with best practices that result and sustain culture change.

‚úÖ Feedback Framework
Systematic approach to collecting and utilizing user feedback through surveys, help desk submissions, calls, user interviews, and other forms of submited feedback directly integrated within the systems. This framework is aimed to ensure that the DQC processes remain adaptive to evolving business needs while continuously improving based on stakeholder experiences and operational realities.

Key Deliverables:
‚Ä¢	‚úÖ Data Quality Control Plan: A detailed document outlining DQC goals, scope, methodology, responsibilities, and timelines.
‚Ä¢	‚úÖ Data Profiling Reports: Comprehensive assessments of critical datasets.
‚Ä¢	‚úÖ Validated and Cleansed Datasets: Ready for use in analytics, reporting, and decision-making.
‚Ä¢	‚úÖ Monitoring Dashboard: Real-time visualization of KPIs and data quality metrics.
‚Ä¢	‚úÖ Training Materials & Sessions: Tailored programs and user manuals for stakeholders.
‚Ä¢	‚úÖ Feedback Framework: Mechanism for capturing improvement suggestions and user experience insights.

Expected Benefits

üìà Better Decision Making Based on Data for all Departments
Every employee of the company will have access to better data which will foster advanced decision-making at all levels. Perception data decision making will be replaced with more reliable and accurate strategic planning.
‚öôÔ∏è Streamlined Industrial Processes and Increased Productivity
Multiple business processes are going to be accomplished in less time due to the elimination of error, inconsistency, and incomplete business transaction management. As a result, employees will devote a greater chunk of time towards value-add activities instead of troubleshooting data conflicts, augmenting productivity as well as performance.
üîí More Efficient Management of Regulatory and Audit Compliance
Ensuring high-quality data translates to policy compliance internally as well as externally with respect to GDPR, SOX, and HIPAA regulations. Adequate supporting documents along with automated constructs for verifying data absence guarantee that ABC Enterprises can with little risk attend to inspection requirements.
üß† Enhanced Employee Engagement in Data Stewardship
With basic training sessions and the promotion of data-keeping habits, employees will appreciate their roles in data quality maintenance. This improvement will create a culture of shared responsibility and provide a solid foundation for a sustainable data stewardship approach across the institution. 
üìä Trustworthy Analytics and AI Projects Supported by High-Quality Data Pipelines
Strong analytics and the application of advanced technologies like machine learning and AI will rest on validated and standardized datasets. If the organization were to enhance the data pipelines by removing noise and inaccuracy, it would ensure that models, forecasts, and dashboards are dependable, justifiable, and operational, thereby fostering innovation and competitive advantage. 
üí° Enhanced Transparency and Business Responsiveness
Leadership will have better insight into the state of enterprise data due to the quality tracking and reporting capabilities. This insight will help with quicker decision-making and swifter response to changes in the market or operational, customer-related demands.

Conclusion:
This Data Quality Control Initiative will serve as a cornerstone for ABC Enterprises‚Äô data governance strategy, enabling trusted, consistent, and actionable data across the enterprise. By embedding best practices, technology, and a culture of quality, the organization positions itself for long-term competitive advantage and digital maturity.


B. Also we have done many weekly activities and in class activities and I am going to paste some screen shot here of our class activates 




üß© Example of Poor-Quality Database in Cloud Computing Context
Dataset Name: Poor_Quality_Dataset_HR
Prepared by: Tizil Raj Choudhary
This dataset is a realistic example of poor data quality commonly encountered in cloud-based databases, especially when data is sourced from disparate systems, manually entered, or migrated without validation. The issues showcased here demonstrate how inconsistent, incomplete, and erroneous data can compromise data integrity and analytics in cloud environments.







 

Field	Examples of Poor Data Quality	Issue Type
ID & Name	- Record 1 and 7 are exact duplicates. 
- Redundant entries with no unique identifiers.	‚ùå Duplicate Records
Age	- Charlie Brown (ID 3) has age -5, which is logically invalid.
- Eve Adams is missing an age value.	‚ùå Outliers, Missing Values
Date of Birth	- Inconsistent formats: 01-02-1993, 1994-05-12, 11/11/1978, etc.
- Lack of standardized encoding.	‚ùå Formatting Inconsistency
Country	- Mixed formats like "USA", "US", and "United States".	‚ùå Inconsistent Values
Income	- Mixed currency formats: $50,000.00, 55000, $100,000.00.
- Missing income for Eve Adams.	‚ùå Formatting, Missing Values
Gender	- Gender values are inconsistent: F, Male, female, M.	‚ùå Inconsistent Categorical Values
Transaction Date	- Different date formats: 2023-02-05, 13-02-2023, 2023.02.10, etc.	‚ùå Granularity & Format Issues
Height (cm)	- Missing height for Eve Adams.	‚ùå Incomplete Data
Satisfaction	- One or more records with missing or out-of-context values.	‚ùå Missing/Irrelevant Data

Week 5 
In this week I understand data enrichment 
What is Data Enrichment?
Data Enrichment is the process of enhancing raw or existing data by supplementing it with additional information from external or internal sources to make it more complete, insightful, and valuable for analysis or decision-making.

üì¶ In Simple Terms:
Imagine you have a basic customer record with just a name and email. Data enrichment adds more depth to that record ‚Äî like their location, age, job title, social media profiles, or past purchasing behavior.

Let me give you an perfect example of data enrichment 
‚úÖ Example of Data Enrichment 
Original Data	After Enrichment
Name: Tizil Raj Choudhary 
Email: tizil@email.com	+ Location: Vancouver / Canada 
+ Job Title: Cloud Computing Analyst 
+ LinkedIn: linkedin.com/in/tizilraj
IP Address: 103.23.45.67	+ Geolocation: Surry / BC / Canada 
+ ISP: rogers 
+ Device: MacBook Pro (M2)
Project ID: CC_Week_9_001	+ Project Area: Data Quality Control 
+ Tools Used: Draw.io, Power BI 
+ Tags: Cloud Computing, Data Profiling, Visualization

This example shows how basic records (name, IP, project ID) can be enriched with contextual metadata, helping systems and users gain more useful insights for analytics, reporting, personalization, or recommendations.
Now I will share the screen shot of activity 
 
And this is draw.io diagram of this activity 
 
I have solved this with the process of ERP 
‚öôÔ∏è How is it Done?
1.	Internal Enrichment:
Pulling additional data from other internal databases or systems within your organization (e.g., CRM, ERP, HRIS).

2.	External Enrichment:
Integrating with third-party data providers (e.g., Clearbit, ZoomInfo, social APIs, government registries).


3.	Automated Enrichment Tools:
Cloud platforms (like AWS DataBrew, Talend, Informatica) or marketing CRMs (like HubSpot, Salesforce) offer automated enrichment capabilities.
üíºERP in Cloud Computing
‚úÖ ERP = Enterprise Resource Planning
ERP is a type of software that helps organizations manage core business processes ‚Äî such as finance, HR, procurement, supply chain, manufacturing, and more ‚Äî in one unified system.
Week 10 

We studies that how and why DAP evaluation is so important 
‚òÅÔ∏è What is DAP in Cloud Computing?
In cloud computing, DAP typically refers to Digital Adoption Platform.
‚úÖ DAP = Digital Adoption Platform
A Digital Adoption Platform is a tool that helps users learn, adopt, and get the most out of software ‚Äî especially cloud-based applications ‚Äî by guiding them through processes with on-screen tutorials, tooltips, walkthroughs, and automation.
 
üìà The Radar Chart:
The chart visually shows how well different best practices are being followed across categories.
‚Ä¢	Points closer to the edge (value = 2) mean strong adoption
‚Ä¢	Points closer to the center (value = 0) mean low or no implementation
‚Ä¢	Helps identify gaps in your DAP/cloud adoption strategy


Summary:
Aspect	What It Tells Us
Evaluation Matrix	Shows progress in implementing cloud best practices
Recommendations	Suggests changes for next semester/course phase
Radar Chart	Visual representation of adoption gaps
Educational or Team Use	Helps both instructors and teams track digital/cloud maturity







